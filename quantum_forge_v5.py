"""
QuantumForge vNext - ä¸»å…¥å£

é‡å­ç®—æ³•ä»£ç ç”Ÿæˆæ¡†æ¶çš„ç»Ÿä¸€å…¥å£ç‚¹ã€‚
åŸºäº5-Agentæ¶æ„ï¼Œå°†è‡ªç„¶è¯­è¨€æŸ¥è¯¢è½¬æ¢ä¸ºå®Œæ•´çš„Pythoné‡å­è®¡ç®—ä»£ç ã€‚
"""

import time
from typing import Dict, Any, Optional
from core.semantic_engine import parse as parse_query
from core.component_discovery import discover as discover_components
from core.parameter_schema_collector import collect_component_parameter_requirements
from core.parameter_matcher import normalize as normalize_params
from core.pipeline_composer import compose as compose_pipeline
from core.execution_memory import create as create_memory
from core.code_assembler import assemble as assemble_code
from core.llm_engine import create_engine
from core.schemas import CodeCell
from core.performance_monitor import get_monitor


def run(query: str, debug=False, max_retries: int = 3, experiment_config: Dict[str, Any] = None) -> str:
    """
    QuantumForge vNextä¸»å…¥å£ - è‡ªç„¶è¯­è¨€æŸ¥è¯¢åˆ°Pythonä»£ç çš„å®Œæ•´è½¬æ¢
    
    Args:
        query: ç”¨æˆ·è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰
        debug: è°ƒè¯•é…ç½® - bool(å¼€å…³) æˆ– dict{"steps": bool, "agents": bool, "performance": bool}
        max_retries: Agenté‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
        experiment_config: å®éªŒé…ç½®ï¼ˆç”¨äºæ¶ˆèå®éªŒï¼‰
        
    Returns:
        å®Œæ•´çš„Pythoné‡å­è®¡ç®—æºç å­—ç¬¦ä¸²
        
    Raises:
        ValueError: æŸ¥è¯¢æ ¼å¼æ— æ•ˆ
        RuntimeError: Agentå¤„ç†å¤±è´¥
    """
    start_time = time.time()
    
    # å¤„ç†è°ƒè¯•é…ç½®
    if isinstance(debug, bool):
        debug_config = {"steps": debug, "agents": False, "performance": debug}
    else:
        debug_config = {
            "steps": debug.get("steps", False),
            "agents": debug.get("agents", False), 
            "performance": debug.get("performance", False)
        }
    
    # åˆå§‹åŒ–æ€§èƒ½ç›‘æ§
    monitor = get_monitor()
    monitor.start_query(query)
    
    # åŠ è½½å®éªŒé…ç½®
    if experiment_config is None:
        from config import ExperimentSettings
        experiment_config = ExperimentSettings.get_experiment_config()
    
    if debug_config["steps"]:
        print(f"ğŸš€ QuantumForge vNext å¯åŠ¨")
        print(f"ğŸ“ æŸ¥è¯¢: {query}")
        if experiment_config.get("ai_completion", {}).get("enabled") == False:
            print(f"ğŸ§ª å®éªŒæ¨¡å¼: AIå‚æ•°è¡¥å…¨å·²ç¦ç”¨")
        if experiment_config.get("robustness", {}).get("simulate_failure"):
            print(f"ğŸ§ª å®éªŒæ¨¡å¼: æ¨¡æ‹Ÿ{experiment_config['robustness']['failed_agent']}Agentå¤±æ•ˆ")
    
    try:
        # Step 1: è¯­ä¹‰ç†è§£ - Query â†’ TaskCard
        if debug_config["steps"]:
            print(f"\nğŸ§  Step 1: è¯­ä¹‰ç†è§£...")
        
        task_card = parse_query(query)
        
        if debug_config["steps"]:
            print(f"ğŸ“‹ TaskCard: {task_card['domain']}.{task_card['problem']}.{task_card['algorithm']}")
        
        # Step 2: ç»„ä»¶å‘ç° - TaskCard â†’ ComponentCards
        if debug_config["steps"]:
            print(f"\nğŸ” Step 2: ç»„ä»¶å‘ç°...")
        
        # æ£€æŸ¥æ˜¯å¦æ¨¡æ‹ŸDiscoveryAgentå¤±æ•ˆ
        if (experiment_config.get("robustness", {}).get("simulate_failure") and 
            experiment_config.get("robustness", {}).get("failed_agent") == "discovery"):
            # æ¨¡æ‹Ÿç»„ä»¶å‘ç°å¤±æ•ˆï¼Œä½¿ç”¨åŸºçº¿ç»„ä»¶
            from core.component_discovery import get_registry_components_by_names
            baseline_names = experiment_config.get("robustness", {}).get("baseline_components", [])
            components = get_registry_components_by_names(baseline_names)
            if debug_config["agents"]:
                print(f"ğŸ§ª æ¨¡æ‹ŸDiscoveryAgentå¤±æ•ˆï¼Œä½¿ç”¨åŸºçº¿ç»„ä»¶: {[comp['name'] for comp in components]}")
        else:
            components = discover_components(task_card)
            if debug_config["steps"]:
                print(f"ğŸ§± å‘ç°ç»„ä»¶: {[comp['name'] for comp in components]}")
        
        # Step 3: å‚æ•°éœ€æ±‚æ”¶é›† - æ”¶é›†ç»„ä»¶å‚æ•°è¦æ±‚
        if debug_config["steps"]:
            print(f"\nğŸ“Š Step 3: å‚æ•°éœ€æ±‚æ”¶é›†...")
        
        param_requirements = collect_component_parameter_requirements(components)
        
        if debug_config["steps"]:
            print(f"ğŸ“‹ å‚æ•°éœ€æ±‚: {param_requirements['total_required_params']}ä¸ªå‚æ•°æ¥è‡ª{param_requirements['total_components']}ä¸ªç»„ä»¶")
        
        # Step 4: AIå‚æ•°è¡¥å…¨ - æ™ºèƒ½è¡¥å…¨ç¼ºå¤±å‚æ•° (æ”¯æŒæ¶ˆèå®éªŒ)
        if debug_config["steps"]:
            print(f"\nğŸ¤– Step 4: AIå‚æ•°è¡¥å…¨...")
        
        # åˆ›å»ºå¼•æ“ï¼ˆæ— è®ºæ˜¯å¦å¯ç”¨AIè¡¥å…¨éƒ½éœ€è¦ï¼Œå› ä¸ºåç»­è¿˜è¦ç”¨äºä»£ç ç”Ÿæˆï¼‰
        engine = create_engine(max_retries=max_retries)
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨AIå‚æ•°è¡¥å…¨ (æ¶ˆèå®éªŒæ§åˆ¶)
        if experiment_config.get("ai_completion", {}).get("enabled", True):
            completed_task_card = engine.complete_parameters(query, task_card, param_requirements)
            
            if debug_config["agents"]:
                original_count = len(task_card.get('params', {}))
                completed_count = len(completed_task_card.get('params', {}))
                print(f"âœ¨ å‚æ•°è¡¥å…¨: {original_count} â†’ {completed_count}ä¸ªå‚æ•°")
        else:
            # æ¶ˆèå®éªŒï¼šç¦ç”¨AIå‚æ•°è¡¥å…¨
            completed_task_card = task_card
            if debug_config["agents"]:
                print(f"ğŸ§ª æ¶ˆèæ¨¡å¼: è·³è¿‡AIå‚æ•°è¡¥å…¨ï¼Œä½¿ç”¨åŸå§‹å‚æ•°")
        
        # Step 5: å‚æ•°å½’ä¸€åŒ– - å¤„ç†åˆ«åå’Œé»˜è®¤å€¼
        if debug_config["steps"]:
            print(f"\nğŸ”§ Step 5: å‚æ•°å½’ä¸€åŒ–...")
        
        # æ£€æŸ¥æ˜¯å¦æ¨¡æ‹ŸParamNormAgentå¤±æ•ˆ
        if (experiment_config.get("robustness", {}).get("simulate_failure") and 
            experiment_config.get("robustness", {}).get("failed_agent") == "param_norm"):
            # æ¨¡æ‹Ÿå‚æ•°å½’ä¸€åŒ–å¤±æ•ˆï¼Œä½¿ç”¨ç®€å•fallback
            param_map = {
                "normalized_params": completed_task_card.get("params", {}),
                "validation_errors": [],
                "fallback_used": True
            }
            if debug_config["steps"]:
                print(f"ğŸ§ª æ¨¡æ‹ŸParamNormAgentå¤±æ•ˆï¼Œä½¿ç”¨ç®€å•å‚æ•°æ˜ å°„: {len(param_map['normalized_params'])}ä¸ª")
        else:
            param_map = normalize_params(completed_task_card, components)
            if debug_config["steps"]:
                if param_map['validation_errors']:
                    print(f"âš ï¸ å‚æ•°è­¦å‘Š: {param_map['validation_errors']}")
                print(f"âœ… å½’ä¸€åŒ–å‚æ•°: {len(param_map['normalized_params'])}ä¸ª")
        
        # Step 6: ç®¡é“ç¼–æ’ - ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        if debug_config["steps"]:
            print(f"\nğŸ“Š Step 6: ç®¡é“ç¼–æ’...")
        
        # æ£€æŸ¥æ˜¯å¦æ¨¡æ‹ŸPipelineAgentå¤±æ•ˆ
        if (experiment_config.get("robustness", {}).get("simulate_failure") and 
            experiment_config.get("robustness", {}).get("failed_agent") == "pipeline"):
            # æ¨¡æ‹Ÿç®¡é“ç¼–æ’å¤±æ•ˆï¼Œä½¿ç”¨ç®€å•fallback
            pipeline_plan = {
                "execution_order": [comp["name"] for comp in components],
                "conflicts": [],
                "dependencies": {},
                "fallback_used": True
            }
            if debug_config["steps"]:
                print(f"ğŸ§ª æ¨¡æ‹ŸPipelineAgentå¤±æ•ˆï¼Œä½¿ç”¨ç®€å•æ‰§è¡Œé¡ºåº: {pipeline_plan['execution_order']}")
        else:
            pipeline_plan = compose_pipeline(completed_task_card, components, param_map)
            if debug_config["steps"]:
                print(f"ğŸ”— æ‰§è¡Œé¡ºåº: {pipeline_plan['execution_order']}")
                if pipeline_plan['conflicts']:
                    print(f"âš ï¸ å†²çª: {pipeline_plan['conflicts']}")
        
        # Step 7: ä»£ç ç”Ÿæˆ - ç”ŸæˆCodeCells
        if debug_config["steps"]:
            print(f"\nğŸ¤– Step 7: ä»£ç ç”Ÿæˆ...")
        
        memory = create_memory()
        
        # è°ƒç”¨CodegenAgentç”ŸæˆCodeCells
        code_cells_data = engine.generate_codecells(pipeline_plan, components, param_map)
        
        # è½¬æ¢ä¸ºCodeCellå¯¹è±¡å¹¶æ·»åŠ åˆ°Memory
        for cell_data in code_cells_data:
            cell = CodeCell(
                id=cell_data["id"],
                imports=cell_data["imports"],
                helpers=cell_data["helpers"],
                definitions=cell_data["definitions"],
                invoke=cell_data["invoke"],
                exports=cell_data["exports"]
            )
            memory.add(cell)
        
        if debug_config["steps"]:
            print(f"ğŸ“¦ ç”ŸæˆCodeCells: {memory.size()}ä¸ª")
        
        # Step 8: ä»£ç è£…é… - ç”Ÿæˆæœ€ç»ˆæºç 
        if debug_config["steps"]:
            print(f"\nğŸ”¨ Step 8: ä»£ç è£…é…...")
        
        final_code = assemble_code(memory, pipeline_plan, task_card, param_map)
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = time.time() - start_time
        
        # ç»“æŸæ€§èƒ½ç›‘æ§
        monitor.end_query()
        
        if debug_config["steps"]:
            print(f"\nâœ… ä»£ç ç”Ÿæˆå®Œæˆ!")
            print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            print(f"ğŸ“ ä»£ç é•¿åº¦: {len(final_code)}å­—ç¬¦")
            
        if debug_config["performance"]:
            # æ˜¾ç¤ºAgentæ€§èƒ½ç»Ÿè®¡
            metrics = monitor.export_metrics()
            print(f"\nğŸ“Š Agentæ€§èƒ½ç»Ÿè®¡:")
            for agent_name, agent_metrics in metrics["agents"].items():
                print(f"  {agent_name}: {agent_metrics['input_tokens']}+{agent_metrics['output_tokens']}={agent_metrics['total_tokens']}tokens, {agent_metrics['call_time']}s")
            totals = metrics["totals"]
            print(f"  æ€»è®¡: {totals['total_tokens']}tokens, {totals['total_agent_time']}s")
        
        return final_code
    
    except Exception as e:
        execution_time = time.time() - start_time
        error_msg = f"QuantumForgeå¤„ç†å¤±è´¥ (è€—æ—¶{execution_time:.2f}s): {str(e)}"
        
        if debug_config["steps"]:
            print(f"âŒ {error_msg}")
        
        raise RuntimeError(error_msg)


def run_and_save(query: str, output_file: str = None, debug=True, max_retries: int = 3) -> str:
    """
    è¿è¡ŒæŸ¥è¯¢å¹¶ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        output_file: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰
        debug: è°ƒè¯•é…ç½® - bool(å¼€å…³) æˆ– dict{"steps": bool, "agents": bool, "performance": bool}
        max_retries: Agenté‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
        
    Returns:
        ç”Ÿæˆçš„ä»£ç å†…å®¹
    """
    # å¤„ç†è°ƒè¯•é…ç½®
    if isinstance(debug, bool):
        debug_config = {"steps": debug, "agents": False, "performance": debug}
    else:
        debug_config = debug
    
    # ç”Ÿæˆä»£ç 
    code = run(query, debug=debug, max_retries=max_retries)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if not output_file:
        import re
        from datetime import datetime
        
        # ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯ä½œä¸ºæ–‡ä»¶å
        clean_query = re.sub(r'[^\w\s]', '', query)
        words = clean_query.split()[:3]  # å–å‰3ä¸ªè¯
        filename_base = "_".join(words).lower()
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"generated_{filename_base}_{timestamp}.py"
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(code)
    
    if debug_config["steps"]:
        print(f"ğŸ’¾ ä»£ç å·²ä¿å­˜åˆ°: {output_file}")
    
    return code


def run_with_metrics(query: str, debug=False, max_retries: int = 3, save_metrics: str = None) -> tuple[str, Dict[str, Any]]:
    """
    è¿è¡ŒæŸ¥è¯¢å¹¶è¿”å›ä»£ç å’Œæ€§èƒ½æŒ‡æ ‡
    
    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        debug: è°ƒè¯•é…ç½® - bool(å¼€å…³) æˆ– dict{"steps": bool, "agents": bool, "performance": bool}
        max_retries: Agenté‡è¯•æ¬¡æ•°
        save_metrics: ä¿å­˜æŒ‡æ ‡çš„æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        (ç”Ÿæˆçš„ä»£ç , æ€§èƒ½æŒ‡æ ‡å­—å…¸)
    """
    # å¤„ç†è°ƒè¯•é…ç½®
    if isinstance(debug, bool):
        debug_config = {"steps": debug, "agents": False, "performance": debug}
    else:
        debug_config = debug
    
    # è¿è¡Œä¸»å‡½æ•°
    code = run(query, debug=debug, max_retries=max_retries)
    
    # è·å–æ€§èƒ½æŒ‡æ ‡
    monitor = get_monitor()
    metrics = monitor.export_metrics()
    
    # ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    if save_metrics:
        import json
        with open(save_metrics, 'w', encoding='utf-8') as f:
            json.dump(metrics, f, ensure_ascii=False, indent=2)
        if debug_config["steps"]:
            print(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜åˆ°: {save_metrics}")
    
    return code, metrics


def get_system_info() -> Dict[str, Any]:
    """
    è·å–ç³»ç»Ÿä¿¡æ¯å’Œç»„ä»¶ç»Ÿè®¡
    
    Returns:
        ç³»ç»Ÿä¿¡æ¯å­—å…¸
    """
    from core.component_discovery import get_registry_stats
    from core.llm_engine import create_engine
    
    try:
        registry_stats = get_registry_stats()
        engine_stats = create_engine().get_agent_stats()
        
        return {
            "version": "vNext",
            "architecture": "5-Agent Pipeline",
            "components": registry_stats,
            "agents": engine_stats,
            "pipeline_stages": [
                "SemanticEngine â†’ TaskCard",
                "ComponentDiscovery â†’ ComponentCards", 
                "ParameterMatcher â†’ ParamMap",
                "PipelineComposer â†’ PipelinePlan",
                "CodeAssembler â†’ Python Code"
            ]
        }
    
    except Exception as e:
        return {"error": str(e)}


def run_ablation_experiment(query: str, experiment_type: str = "ai_completion", debug: bool = True) -> Dict[str, Any]:
    """
    è¿è¡Œæ¶ˆèå®éªŒï¼Œæ¯”è¾ƒä¸åŒé…ç½®ä¸‹çš„ç³»ç»Ÿè¡¨ç°
    
    Args:
        query: æµ‹è¯•æŸ¥è¯¢
        experiment_type: å®éªŒç±»å‹ "ai_completion" | "agent_robustness"
        debug: æ˜¯å¦æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        
    Returns:
        å®éªŒç»“æœå­—å…¸
    """
    from config import ExperimentSettings
    
    results = {"experiment_type": experiment_type, "query": query, "results": {}}
    
    if experiment_type == "ai_completion":
        print(f"ğŸ§ª AIå‚æ•°è¡¥å…¨æ¶ˆèå®éªŒ")
        print(f"ğŸ“ æŸ¥è¯¢: {query}\n")
        
        # å¯¹ç…§ç»„: ç¦ç”¨AIå‚æ•°è¡¥å…¨
        control_config = {"ai_completion": {"enabled": False}}
        print("ğŸ“Š å¯¹ç…§ç»„ (æ— AIè¡¥å…¨):")
        try:
            start_time = time.time()
            control_code = run(query, debug=debug, experiment_config=control_config)
            control_time = time.time() - start_time
            
            results["results"]["control"] = {
                "success": True,
                "execution_time": control_time,
                "code_length": len(control_code),
                "param_count": control_code.count("=") # ç®€å•å‚æ•°è®¡æ•°
            }
            print(f"âœ… å¯¹ç…§ç»„å®Œæˆ: {control_time:.2f}s, {len(control_code)}å­—ç¬¦\n")
            
        except Exception as e:
            results["results"]["control"] = {"success": False, "error": str(e)}
            print(f"âŒ å¯¹ç…§ç»„å¤±è´¥: {e}\n")
        
        # å®éªŒç»„: å¯ç”¨AIå‚æ•°è¡¥å…¨  
        experiment_config = {"ai_completion": {"enabled": True}}
        print("ğŸ“Š å®éªŒç»„ (æœ‰AIè¡¥å…¨):")
        try:
            start_time = time.time()
            experiment_code = run(query, debug=debug, experiment_config=experiment_config)
            experiment_time = time.time() - start_time
            
            results["results"]["experiment"] = {
                "success": True,
                "execution_time": experiment_time,
                "code_length": len(experiment_code),
                "param_count": experiment_code.count("=")
            }
            print(f"âœ… å®éªŒç»„å®Œæˆ: {experiment_time:.2f}s, {len(experiment_code)}å­—ç¬¦")
            
        except Exception as e:
            results["results"]["experiment"] = {"success": False, "error": str(e)}
            print(f"âŒ å®éªŒç»„å¤±è´¥: {e}")
    
    elif experiment_type == "agent_robustness":
        print(f"ğŸ§ª Agenté²æ£’æ€§å®éªŒ")
        print(f"ğŸ“ æŸ¥è¯¢: {query}\n")
        
        # å¯¹ç…§ç»„: æ­£å¸¸è¿è¡Œæ‰€æœ‰Agent
        control_config = {"robustness": {"simulate_failure": False, "failed_agent": None}}
        print("ğŸ“Š å¯¹ç…§ç»„ (æ‰€æœ‰Agentæ­£å¸¸):")
        try:
            start_time = time.time()
            control_code = run(query, debug=debug, experiment_config=control_config)
            control_time = time.time() - start_time
            
            results["results"]["control"] = {
                "success": True,
                "execution_time": control_time,
                "code_length": len(control_code),
                "failed_agent": None
            }
            print(f"âœ… å¯¹ç…§ç»„å®Œæˆ: {control_time:.2f}s, {len(control_code)}å­—ç¬¦\n")
            
        except Exception as e:
            results["results"]["control"] = {"success": False, "error": str(e), "failed_agent": None}
            print(f"âŒ å¯¹ç…§ç»„å¤±è´¥: {e}\n")
        
        # å®éªŒç»„: æ¨¡æ‹Ÿä¸åŒAgentå¤±æ•ˆ
        failed_agents = ["discovery", "param_norm", "pipeline"]
        
        for failed_agent in failed_agents:
            experiment_config = {
                "robustness": {
                    "simulate_failure": True,
                    "failed_agent": failed_agent,
                    "baseline_components": ExperimentSettings.BASELINE_COMPONENTS
                }
            }
            
            print(f"ğŸ“Š å®éªŒç»„ ({failed_agent}Agentå¤±æ•ˆ):")
            try:
                start_time = time.time()
                experiment_code = run(query, debug=debug, experiment_config=experiment_config)
                experiment_time = time.time() - start_time
                
                results["results"][f"failed_{failed_agent}"] = {
                    "success": True,
                    "execution_time": experiment_time,
                    "code_length": len(experiment_code),
                    "failed_agent": failed_agent
                }
                print(f"âœ… å®éªŒç»„å®Œæˆ: {experiment_time:.2f}s, {len(experiment_code)}å­—ç¬¦")
                
            except Exception as e:
                results["results"][f"failed_{failed_agent}"] = {
                    "success": False, 
                    "error": str(e),
                    "failed_agent": failed_agent
                }
                print(f"âŒ å®éªŒç»„å¤±è´¥: {e}")
            
            print()  # ç©ºè¡Œåˆ†éš”
    
    return results


# =============================================================================
# æµ‹è¯•ä»£ç 
# =============================================================================

if __name__ == "__main__":
    print("ğŸš€ QuantumForge vNext ç«¯åˆ°ç«¯æµ‹è¯•")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "å¸®æˆ‘è®¡ç®—8æ¯”ç‰¹TFIMçš„åŸºæ€èƒ½é‡",
        "ä½¿ç”¨VQEç®—æ³•è®¡ç®—10æ¯”ç‰¹TFIMåŸºæ€ï¼Œæ¨ªå‘åœºå¼ºåº¦1.5"
    ]
    
    for query in test_queries:
        print(f"\n" + "="*60)
        print(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: {query}")
        print("="*60)
        
        try:
            # è¿è¡Œå®Œæ•´ç®¡é“
            generated_code = run(query, debug=True)
            
            # æ˜¾ç¤ºç”Ÿæˆçš„ä»£ç ç‰‡æ®µ
            lines = generated_code.split('\n')
            print(f"\nğŸ“„ ç”Ÿæˆçš„ä»£ç é¢„è§ˆ (å‰20è¡Œ):")
            print("-" * 50)
            for i, line in enumerate(lines[:20]):
                print(f"{i+1:2d}: {line}")
            if len(lines) > 20:
                print(f"... (è¿˜æœ‰{len(lines)-20}è¡Œ)")
            print("-" * 50)
            
            print(f"ğŸ‰ æŸ¥è¯¢å¤„ç†æˆåŠŸï¼")
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
    
    # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
    print(f"\nğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
    system_info = get_system_info()
    for key, value in system_info.items():
        if isinstance(value, dict):
            print(f"  {key}: {len(value) if 'components' in key else value}")
        elif isinstance(value, list):
            print(f"  {key}: {len(value)}é¡¹")
        else:
            print(f"  {key}: {value}")