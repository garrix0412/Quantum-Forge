"""
LLMå¼•æ“ - QuantumForge vNext

æä¾›äº”ä¸ªä¸“é—¨çš„Agent APIï¼Œå¤„ç†æ‰€æœ‰LLMé€šä¿¡ã€‚
åŸºäºnew.mdç¬¬4.2èŠ‚å’Œç¬¬5èŠ‚çš„ä¸¥æ ¼JSONè§„æ ¼å®ç°ã€‚
"""

import json
import time
import asyncio
from typing import Dict, List, Any, Optional
from openai import OpenAI, AsyncOpenAI
import os
from dotenv import load_dotenv
try:
    from .performance_monitor import record_agent_call
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶çš„å…¼å®¹å¤„ç†
    import sys
    sys.path.append(os.path.dirname(__file__))
    from performance_monitor import record_agent_call

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class LLMEngine:
    """
    LLMå¼•æ“ - äº”ä¸ªAgent APIçš„ç»Ÿä¸€æ¥å£
    
    åŠŸèƒ½ï¼š
    - ä¸¥æ ¼JSONè§£æä¸é‡è¯•æœºåˆ¶
    - Agentå¤±è´¥æ£€æµ‹ä¸ä¼˜é›…é™çº§
    - é’ˆå¯¹æ¯ä¸ªè§’è‰²ä¼˜åŒ–çš„æç¤ºè¯æ¨¡æ¿
    """
    
    def __init__(self, api_key: Optional[str] = None, max_retries: int = 3):
        """
        åˆå§‹åŒ–LLMå¼•æ“
        
        Args:
            api_key: OpenAI APIå¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡è‡ªåŠ¨è·å–ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.max_retries = max_retries
        
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼ˆåŒæ­¥å’Œå¼‚æ­¥ï¼‰
        self.client = OpenAI(api_key=self.api_key)
        self.async_client = AsyncOpenAI(api_key=self.api_key)
        
        # Agentæç¤ºè¯æ¨¡æ¿ï¼ˆåŸºäºnew.mdç¬¬5èŠ‚ï¼‰
        self._setup_agent_prompts()
    
    def _setup_agent_prompts(self):
        """è®¾ç½®Agentæç¤ºè¯æ¨¡æ¿"""
        
        self.semantic_prompt = """You are a quantum computing task analyzer. Parse natural language queries into structured TaskCard JSON format.

Required JSON keys: domain, problem, algorithm, backend, params
- domain: "spin.tfim" | "spin.heisenberg" | "spin.ising" | "chemistry.molecular" | "optimization" | "custom"
- backend: always "qiskit"
- Extract explicit parameters from query only, do not add defaults (component-driven completion will handle missing parameters)

DOMAIN CLASSIFICATION RULES:
- If query mentions "heisenberg" or has Jx,Jy,Jz parameters â†’ "spin.heisenberg"
- If query mentions "tfim", "transverse field" or has hx,j parameters â†’ "spin.tfim"  
- If query mentions "ising" â†’ "spin.ising"
- If query mentions molecular names (LiH, BeH2, H2O) or molecular terms â†’ "chemistry.molecular"
- Other spin systems â†’ "spin"

CRITICAL: You must respond with ONLY valid JSON, no explanatory text before or after.

Example:
Input: "Compute the ground state energy of a 4-qubit system using VQE"
Output: {"domain": "spin", "problem": "ground_state_energy", "algorithm": "vqe", "backend": "qiskit", "params": {"n": 4}}

Input: "Calculate Heisenberg model ground state with Jx=1.0"  
Output: {"domain": "spin.heisenberg", "problem": "ground_state_energy", "algorithm": "vqe", "backend": "qiskit", "params": {"Jx": 1.0}}"""

        self.discovery_prompt = """You are a quantum component discovery agent. Select appropriate components from the registry to satisfy TaskCard requirements.

Based on TaskCard, select components that cover the needs/provides dependency chain.
Return ComponentCard JSON array format, preserving ALL fields from registry exactly as they appear.
Prioritize algorithm-matching components (e.g., vqe â†’ Algorithm.VQE) and domain-appropriate hamiltonians/circuits.

CRITICAL FIELD PRESERVATION - NO MODIFICATIONS ALLOWED:
1. Copy EVERY field from registry components exactly as written
2. Do NOT shorten function names (keep build_molecular_hamiltonian, NOT build_molecular_h)
3. Do NOT change helper_function values (keep build_uccsd_ansatz, NOT uccsd)
4. Do NOT infer or modify codegen_hint.helper values
5. Preserve helper_function, invoke_template, codegen_hint fields completely
6. Return components as exact copies from registry with no modifications

Example of CORRECT preservation:
Registry: "helper_function": "build_molecular_hamiltonian"  
Output: "helper_function": "build_molecular_hamiltonian" âœ…

Example of INCORRECT modification:
Registry: "helper_function": "build_molecular_hamiltonian"
Output: "helper_function": "build_molecular_h" âŒ

DOMAIN-BASED COMPONENT SELECTION:
- domain "spin.heisenberg" â†’ select Hamiltonian.Heisenberg + Circuit.Heisenberg_Ansatz
- domain "spin.tfim" â†’ select Hamiltonian.TFIM + Circuit.TFIM_HEA
- domain "spin.ising" â†’ select appropriate Ising components
- domain "chemistry.molecular" â†’ select Hamiltonian.Molecular + Circuit.UCCSD + Algorithm.Molecular_VQE
- domain "spin" â†’ select based on available parameters and context

CRITICAL: You must respond with ONLY valid JSON, no explanatory text before or after.
CRITICAL: Copy ALL fields from registry components exactly, including helper_function, invoke_template, codegen_hint, params_schema, etc.

Output: Complete component objects from registry (preserve all fields)"""

        self.param_norm_prompt = """You are a quantum parameter normalization agent. Generate ParamMap JSON based on TaskCard and ComponentCards.

CRITICAL TASK: Collect ALL parameters from BOTH TaskCard AND ComponentCards params_schema fields.

Process steps:
1. Extract parameters from TaskCard.params (user-provided)
2. Extract ALL parameters from each ComponentCard.params_schema (component requirements)  
3. Merge all parameters into normalized_params (TaskCard params override ComponentCard defaults)
4. Apply alias resolution and type validation
5. Generate comprehensive defaults from component schemas

PARAMETER COLLECTION RULES:
- Include EVERY parameter from ALL ComponentCard params_schema fields
- Use TaskCard.params values when available (user override)
- Use ComponentCard.params_schema.default values for missing parameters
- Preserve parameter names exactly as defined in schemas

Example:
TaskCard.params: {"molecule": "BeH2"}
Component1.params_schema: {"molecule": {"default": "LiH"}, "atom_string": {"default": "Li 0 0 0; H 0 0 0.735"}}
Result normalized_params: {"molecule": "BeH2", "atom_string": "Li 0 0 0; H 0 0 0.735"}

CRITICAL: You must respond with ONLY valid JSON, no explanatory text before or after.

Output format: {"normalized_params": {}, "aliases": {}, "defaults": {}, "validation_errors": []}"""

        self.pipeline_prompt = """You are a quantum pipeline orchestration agent. Generate PipelinePlan JSON based on TaskCard, ComponentCards, and ParamMap.

Implement linear topological sorting to resolve component dependencies.
Analyze needs/provides relationships to create proper execution order.

CRITICAL: You must respond with ONLY valid JSON, no explanatory text before or after.

Output format: {"execution_order": ["component_id_list"], "dependency_graph": {}, "conflicts": []}"""

        self.codegen_prompt = """You are a quantum code generation agent. Generate CodeCell list based on PipelinePlan, ComponentCards, and ParamMap.

Each component corresponds to one CodeCell with imports, helpers, definitions, invoke, and exports.

Critical: invoke field must be valid Python statements, not dictionary assignment syntax.

IMPORT RULES - CRITICAL:
- Use ONLY imports from ComponentImports list provided in user message
- Do NOT add any other imports, even if they seem related to quantum computing
- Do NOT add qiskit_nature imports unless they appear in ComponentImports
- Do NOT infer imports from function names or quantum computing knowledge
- ComponentImports contains the complete and exclusive import list

IMPORTANT: Use the exact helper_function name from each component's schema, not generic names.

Correct examples:
- Use component's helper_function: "H = build_tfim_h(n, hx, j, boundary)" (from TFIM schema)
- Use component's helper_function: "ansatz = heisenberg_ansatz(n, reps)" (from Heisenberg schema)  
- Use component's helper_function: "H, problem, mapper = build_molecular_hamiltonian(molecule, basis_set, atom_string, charge, spin)" (from Molecular schema)

Incorrect examples:
- Generic names: "H = build_hamiltonian(n, hx, j, boundary)" âŒ
- Generic names: "ansatz = create_ansatz(n, reps)" âŒ
- Dictionary syntax: "{'n': 'n', 'hx': 'h'} = Component.Name" âŒ

Parameter usage:
- Use normalized_params from ParamMap as actual parameter names
- Directly use standard parameter names in invoke code (e.g., n, hx, j)
- Do not create parameter alias assignments

Component instance usage:
- Algorithm components receive other component instances as arguments
- Use created component variables (e.g., optimizer, estimator) not parameter values
- Example: run_vqe(H, ansatz, optimizer, estimator) where optimizer and estimator are component instances

CRITICAL: You must respond with ONLY valid JSON, no explanatory text before or after.

Output strict JSON array format:
[{"id": "cell_id", "imports": ["import_statements"], "helpers": ["helper_functions"], "definitions": ["definitions"], "invoke": "invoke_code", "exports": {"variable_mapping"}}]"""

        self.param_completion_prompt = """You are a quantum computing parameter completion expert. Intelligently complete missing parameters based on query analysis and domain expertise.

Input context:
- User query: Natural language description of the quantum computing task
- Domain: Type of quantum system (spin/chemistry/optimization/custom)
- Algorithm: Selected quantum algorithm (vqe/qaoa/qpe/etc)
- Selected components: Available components with their parameter schemas
- Provided parameters: Parameters explicitly mentioned in query
- Missing parameters: Parameters required by components but not provided

Analyze the user's intent and requirements to determine optimal parameter values:
- For optimization algorithms: Judge iteration needs based on problem complexity and precision requirements
- For quantum systems: Select appropriate parameter values based on physical understanding
- For computational methods: Choose parameters that balance accuracy with computational feasibility
- Prioritize accuracy and convergence quality when in doubt

Use your quantum computing expertise to select the most appropriate values for the given context.

CRITICAL: You must respond with ONLY valid JSON, no explanatory text before or after.

Output format: {"completed_params": {"param_name": value, ...}, "completion_rationale": "brief explanation"}"""
    
    def _call_openai(self, system_prompt: str, user_message: str, agent_name: str = None) -> str:
        """
        è°ƒç”¨OpenAI API (åŒæ­¥ç‰ˆæœ¬)
        
        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_message: ç”¨æˆ·æ¶ˆæ¯
            agent_name: Agentåç§°ï¼ˆç”¨äºæ€§èƒ½ç›‘æ§ï¼‰
            
        Returns:
            APIå“åº”å†…å®¹
        """
        try:
            start_time = time.time()
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ]
            )
            
            call_time = time.time() - start_time
            content = response.choices[0].message.content.strip()
            
            # è®°å½•æ€§èƒ½æ•°æ®
            if agent_name:
                input_tokens = response.usage.prompt_tokens if response.usage else 0
                output_tokens = response.usage.completion_tokens if response.usage else 0
                record_agent_call(agent_name, system_prompt + user_message, content, call_time, "gpt-4o-mini")
                
                # æ›´æ–°ç²¾ç¡®çš„tokenæ•°æ®
                from .performance_monitor import get_monitor
                metrics = get_monitor().get_agent_metrics(agent_name)
                metrics.set_tokens(input_tokens, output_tokens)
            
            return content
        
        except Exception as e:
            raise RuntimeError(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    async def _call_openai_async(self, system_prompt: str, user_message: str) -> str:
        """
        è°ƒç”¨OpenAI API (å¼‚æ­¥ç‰ˆæœ¬)
        
        Args:
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            user_message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            APIå“åº”å†…å®¹
        """
        try:
            response = await self.async_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ]
            )
            
            return response.choices[0].message.content.strip()
        
        except Exception as e:
            raise RuntimeError(f"OpenAI APIå¼‚æ­¥è°ƒç”¨å¤±è´¥: {str(e)}")
    
    def _parse_json_with_retry(self, response_text: str, agent_name: str) -> Any:
        """
        ä¸¥æ ¼JSONè§£æï¼Œæ”¯æŒé‡è¯•
        
        Args:
            response_text: LLMå“åº”æ–‡æœ¬
            agent_name: Agentåç§°ï¼ˆç”¨äºé”™è¯¯æŠ¥å‘Šï¼‰
            
        Returns:
            è§£æåçš„JSONå¯¹è±¡
            
        Raises:
            ValueError: JSONè§£æå¤±è´¥ä¸”é‡è¯•è¶…è¿‡é™åˆ¶
        """
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼ˆç§»é™¤å¯èƒ½çš„markdownæ ‡è®°ï¼‰
            cleaned_text = response_text.strip()
            if cleaned_text.startswith("```json"):
                cleaned_text = cleaned_text[7:]
            if cleaned_text.endswith("```"):
                cleaned_text = cleaned_text[:-3]
            cleaned_text = cleaned_text.strip()
            
            return json.loads(cleaned_text)
        
        except json.JSONDecodeError as e:
            raise ValueError(f"{agent_name} Agentè¿”å›äº†æ— æ•ˆçš„JSON: {str(e)}\nåŸå§‹å“åº”: {response_text[:200]}...")
    
    def _validate_task_card(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯TaskCardæ ¼å¼"""
        required_fields = ["domain", "problem", "algorithm", "backend", "params"]
        valid_domains = {"spin", "spin.tfim", "spin.heisenberg", "spin.ising", "chemistry.molecular", "optimization", "custom"}
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in required_fields:
            if field not in data:
                return False
        
        # æ£€æŸ¥domainæšä¸¾å€¼
        if data["domain"] not in valid_domains:
            return False
        
        # æ£€æŸ¥backendå›ºå®šå€¼
        if data["backend"] != "qiskit":
            return False
        
        return True
    
    def _validate_component_cards(self, data: List[Dict[str, Any]]) -> bool:
        """éªŒè¯ComponentCardsæ ¼å¼"""
        if not isinstance(data, list):
            return False
        
        required_fields = ["name", "kind", "tags", "needs", "provides", "params_schema", "yields", "codegen_hint"]
        
        for card in data:
            if not isinstance(card, dict):
                return False
            for field in required_fields:
                if field not in card:
                    return False
        
        return True
    
    def _validate_param_map(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯ParamMapæ ¼å¼"""
        required_fields = ["normalized_params", "aliases", "defaults", "validation_errors"]
        
        for field in required_fields:
            if field not in data:
                return False
        
        return True
    
    def _validate_pipeline_plan(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯PipelinePlanæ ¼å¼"""
        required_fields = ["execution_order", "dependency_graph", "conflicts"]
        
        for field in required_fields:
            if field not in data:
                return False
        
        # execution_orderåº”è¯¥æ˜¯åˆ—è¡¨
        if not isinstance(data["execution_order"], list):
            return False
        
        return True
    
    def _validate_code_cells(self, data: List[Dict[str, Any]]) -> bool:
        """éªŒè¯CodeCellsæ ¼å¼å’Œinvokeè¯­æ³•"""
        if not isinstance(data, list):
            return False
        
        required_fields = ["id", "imports", "helpers", "definitions", "invoke", "exports"]
        
        for cell in data:
            if not isinstance(cell, dict):
                return False
            for field in required_fields:
                if field not in cell:
                    return False
            
            # éªŒè¯invokeä»£ç è¯­æ³•
            invoke_code = cell.get("invoke", "")
            if invoke_code and not self._validate_invoke_syntax(invoke_code):
                print(f"âš ï¸ Invalid invoke syntax in {cell.get('id', 'unknown')}: {invoke_code}")
                return False
        
        return True
    
    def _validate_invoke_syntax(self, invoke_code: str) -> bool:
        """éªŒè¯invokeä»£ç çš„è¯­æ³•æ­£ç¡®æ€§"""
        import re
        
        # æ£€æŸ¥å¸¸è§çš„é”™è¯¯æ¨¡å¼
        invalid_patterns = [
            r'\{.*\}\s*=',  # å­—å…¸èµ‹å€¼è¯­æ³• {'n': 'n'} =
            r'=\s*\{.*\}$',  # ä»¥å­—å…¸ç»“å°¾çš„èµ‹å€¼ = {'n': 'n'}
            r'\[\s*\]\s*=',  # ç©ºåˆ—è¡¨èµ‹å€¼ [] =
            r'=\s*\[\s*\]$'  # ä»¥ç©ºåˆ—è¡¨ç»“å°¾ = []
        ]
        
        for pattern in invalid_patterns:
            if re.search(pattern, invoke_code):
                return False
        
        # åŸºæœ¬è¯­æ³•æ£€æŸ¥
        try:
            compile(invoke_code, '<invoke>', 'exec')
            return True
        except SyntaxError:
            return False

    # =============================================================================
    # äº”ä¸ªAgent API
    # =============================================================================
    
    def task_understanding(self, query: str) -> Dict[str, Any]:
        """
        Agent 1: ä»»åŠ¡ç†è§£ - Query â†’ TaskCard
        
        Args:
            query: ç”¨æˆ·è‡ªç„¶è¯­è¨€æŸ¥è¯¢
            
        Returns:
            TaskCardå­—å…¸
        """
        for attempt in range(self.max_retries):
            try:
                response = self._call_openai(self.semantic_prompt, query, "SemanticAgent")
                parsed_data = self._parse_json_with_retry(response, "SemanticAgent")
                
                if self._validate_task_card(parsed_data):
                    return parsed_data
                else:
                    raise ValueError("TaskCardæ ¼å¼éªŒè¯å¤±è´¥")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"SemanticAgentå¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}")
                
                print(f"âš ï¸ SemanticAgenté‡è¯• {attempt + 1}/{self.max_retries}: {str(e)}")
                time.sleep(0.5)
    
    def discover_components(self, task_card: Dict[str, Any], registry_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Agent 2: ç»„ä»¶å‘ç° - TaskCard â†’ ComponentCards
        
        Args:
            task_card: ä»»åŠ¡å¡
            registry_data: ç»„ä»¶æ³¨å†Œè¡¨æ•°æ®
            
        Returns:
            ComponentCardåˆ—è¡¨
        """
        user_message = f"""TaskCard: {json.dumps(task_card, ensure_ascii=False)}

Component Registry:
{json.dumps(registry_data, ensure_ascii=False, indent=2)}

Please select appropriate components from the registry to satisfy this task requirement."""
        
        for attempt in range(self.max_retries):
            try:
                response = self._call_openai(self.discovery_prompt, user_message, "DiscoveryAgent")
                parsed_data = self._parse_json_with_retry(response, "DiscoveryAgent")
                
                if self._validate_component_cards(parsed_data):
                    return parsed_data
                else:
                    raise ValueError("ComponentCardsæ ¼å¼éªŒè¯å¤±è´¥")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"DiscoveryAgentå¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}")
                
                print(f"âš ï¸ DiscoveryAgenté‡è¯• {attempt + 1}/{self.max_retries}: {str(e)}")
                time.sleep(0.5)
    
    def normalize_params(self, task_card: Dict[str, Any], components: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Agent 3: å‚æ•°å½’ä¸€åŒ– - å¤„ç†åˆ«åã€é»˜è®¤å€¼ã€éªŒè¯
        
        Args:
            task_card: ä»»åŠ¡å¡
            components: ç»„ä»¶åˆ—è¡¨
            
        Returns:
            ParamMapå­—å…¸
        """
        user_message = f"""TaskCard: {json.dumps(task_card, ensure_ascii=False)}

ComponentCards: {json.dumps(components, ensure_ascii=False, indent=2)}

Please process parameter normalization, including alias resolution, default value injection, and basic validation."""
        
        for attempt in range(self.max_retries):
            try:
                response = self._call_openai(self.param_norm_prompt, user_message, "ParamNormAgent")
                parsed_data = self._parse_json_with_retry(response, "ParamNormAgent")
                
                if self._validate_param_map(parsed_data):
                    return parsed_data
                else:
                    raise ValueError("ParamMapæ ¼å¼éªŒè¯å¤±è´¥")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"ParamNormAgentå¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}")
                
                print(f"âš ï¸ ParamNormAgenté‡è¯• {attempt + 1}/{self.max_retries}: {str(e)}")
                time.sleep(0.5)
    
    def plan_pipeline(self, task_card: Dict[str, Any], components: List[Dict[str, Any]], param_map: Dict[str, Any]) -> Dict[str, Any]:
        """
        Agent 4: ç®¡é“ç¼–æ’ - ç”ŸæˆPipelinePlan
        
        Args:
            task_card: ä»»åŠ¡å¡
            components: ç»„ä»¶åˆ—è¡¨
            param_map: å‚æ•°æ˜ å°„
            
        Returns:
            PipelinePlanå­—å…¸
        """
        user_message = f"""TaskCard: {json.dumps(task_card, ensure_ascii=False)}

ComponentCards: {json.dumps(components, ensure_ascii=False, indent=2)}

ParamMap: {json.dumps(param_map, ensure_ascii=False)}

Please generate a linear execution pipeline plan based on component needs/provides dependencies."""
        
        for attempt in range(self.max_retries):
            try:
                response = self._call_openai(self.pipeline_prompt, user_message, "PipelineAgent")
                parsed_data = self._parse_json_with_retry(response, "PipelineAgent")
                
                if self._validate_pipeline_plan(parsed_data):
                    return parsed_data
                else:
                    raise ValueError("PipelinePlanæ ¼å¼éªŒè¯å¤±è´¥")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"PipelineAgentå¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}")
                
                print(f"âš ï¸ PipelineAgenté‡è¯• {attempt + 1}/{self.max_retries}: {str(e)}")
                time.sleep(0.5)
    
    def complete_parameters(self, query: str, task_card: Dict[str, Any], required_schema: Dict[str, Any]) -> Dict[str, Any]:
        """
        Agent 6: å‚æ•°è¡¥å…¨ - åŸºäºç»„ä»¶éœ€æ±‚æ™ºèƒ½è¡¥å…¨ç¼ºå¤±å‚æ•°
        
        Args:
            query: åŸå§‹ç”¨æˆ·æŸ¥è¯¢
            task_card: åŸºç¡€ä»»åŠ¡å¡
            required_schema: ç»„ä»¶å‚æ•°éœ€æ±‚schema
            
        Returns:
            è¡¥å…¨åçš„å‚æ•°å­—å…¸
        """
        user_params = task_card.get("params", {})
        missing_params = set(required_schema.keys()) - set(user_params.keys())
        
        # å¦‚æœæ²¡æœ‰ç¼ºå¤±å‚æ•°ï¼Œç›´æ¥è¿”å›
        if not missing_params:
            return user_params
        
        # æ„å»ºè¡¥å…¨ä¸Šä¸‹æ–‡
        user_message = f"""Query: {query}

Domain: {task_card.get('domain')}
Algorithm: {task_card.get('algorithm')}
Provided Parameters: {json.dumps(user_params, ensure_ascii=False)}
Required Parameters Schema: {json.dumps(required_schema, ensure_ascii=False)}
Missing Parameters: {list(missing_params)}

Please complete the missing parameters with appropriate quantum computing defaults."""

        for attempt in range(self.max_retries):
            try:
                response = self._call_openai(self.param_completion_prompt, user_message, "ParamCompletionAgent")
                parsed_data = self._parse_json_with_retry(response, "ParamCompletionAgent")
                
                validation_result = self._validate_parameter_completion(
                    parsed_data.get("completed_params", {}), 
                    required_schema
                )
                
                if validation_result["valid"]:
                    # åˆå¹¶ç”¨æˆ·å‚æ•°å’Œè¡¥å…¨å‚æ•°
                    completed_params = user_params.copy()
                    completed_params.update(validation_result["validated_params"])
                    
                    # åˆ›å»ºæ–°çš„task_card
                    completed_task_card = task_card.copy()
                    completed_task_card["params"] = completed_params
                    return completed_task_card
                else:
                    raise ValueError("Parameter completion format validation failed")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"ParamCompletionAgent failed after {self.max_retries} retries: {str(e)}")
                
                print(f"âš ï¸ ParamCompletionAgent retry {attempt + 1}/{self.max_retries}: {str(e)}")
                time.sleep(0.5)

    def _get_helper_signature(self, helper_name: str) -> str:
        """
        åŠ¨æ€è·å–helperå‡½æ•°çš„ç­¾å
        
        Args:
            helper_name: helperå‡½æ•°å
            
        Returns:
            å‡½æ•°ç­¾åå­—ç¬¦ä¸²ï¼Œå¦‚ "run_vqe(hamiltonian, ansatz, optimizer, estimator)"
        """
        try:
            # å°è¯•ä»helperæ–‡ä»¶ä¸­åŠ è½½å‡½æ•°å¹¶è·å–ç­¾å
            from .helper_loader import load_single_helper
            import inspect
            
            helper_func = load_single_helper(helper_name)
            if helper_func:
                sig = inspect.signature(helper_func)
                return f"{helper_name}{sig}"
        except Exception:
            # å¦‚æœåŠ¨æ€è·å–å¤±è´¥ï¼Œè¿”å›Noneè®©CodegenAgentè‡ªå·±å¤„ç†
            pass
        
        return None

    def _get_helper_source(self, helper_name: str, component_names: list = None) -> str:
        """
        æ ¹æ®ç»„ä»¶ç±»å‹éš”ç¦»æŸ¥æ‰¾helperå‡½æ•°æºä»£ç 
        
        Args:
            helper_name: helperå‡½æ•°å
            component_names: å½“å‰ä½¿ç”¨çš„ç»„ä»¶ååˆ—è¡¨ï¼Œç”¨äºç¡®å®šæŸ¥æ‰¾èŒƒå›´
            
        Returns:
            çº¯å‡½æ•°å®šä¹‰æºä»£ç å­—ç¬¦ä¸²ï¼Œä¸åŒ…å«æ–‡ä»¶å¯¼å…¥
        """
        try:
            from .helper_loader import _find_helper_files
            import ast
            import os
            
            # æ ¹æ®ç»„ä»¶ç±»å‹ç¡®å®šæŸ¥æ‰¾èŒƒå›´
            allowed_files = self._get_allowed_helper_files(component_names)
            
            helper_files = _find_helper_files()
            for helper_file in helper_files:
                # åªæŸ¥æ‰¾å…è®¸çš„helperæ–‡ä»¶ï¼Œé¿å…è·¨ç»„ä»¶æ±¡æŸ“  
                helper_filename = os.path.basename(str(helper_file))
                if allowed_files and helper_filename not in allowed_files:
                    continue
                    
                with open(helper_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                tree = ast.parse(content)
                for node in tree.body:
                    if isinstance(node, ast.FunctionDef) and node.name == helper_name:
                        # åªè¿”å›å‡½æ•°å®šä¹‰ï¼Œé¿å…å¯¼å…¥æ±¡æŸ“
                        return ast.unparse(node)
        except Exception:
            pass
        
        return None
    
    def _detect_typing_imports(self, params_schema: Dict[str, Any]) -> set:
        """
        è‡ªåŠ¨æ£€æµ‹å‚æ•°schemaä¸­éœ€è¦çš„typing imports
        
        Args:
            params_schema: ç»„ä»¶å‚æ•°schema
            
        Returns:
            set: éœ€è¦çš„typing importè¯­å¥
        """
        PYTHON_TYPE_IMPORTS = {
            "Dict": "from typing import Dict",
            "List": "from typing import List", 
            "Optional": "from typing import Optional",
            "Union": "from typing import Union",
            "Tuple": "from typing import Tuple",
            "Any": "from typing import Any",
            "Callable": "from typing import Callable"
        }
        
        needed_imports = set()
        for param_info in params_schema.values():
            param_type = param_info.get("type", "")
            if param_type in PYTHON_TYPE_IMPORTS:
                needed_imports.add(PYTHON_TYPE_IMPORTS[param_type])
        
        return needed_imports
    
    def _detect_typing_from_code(self, code_content: str) -> set:
        """
        ä»ç”Ÿæˆçš„ä»£ç å†…å®¹ä¸­æ£€æµ‹éœ€è¦çš„typing imports
        
        Args:
            code_content: ç”Ÿæˆçš„Pythonä»£ç å†…å®¹
            
        Returns:
            set: éœ€è¦çš„typing importè¯­å¥
        """
        PYTHON_TYPE_IMPORTS = {
            "Dict": "from typing import Dict",
            "List": "from typing import List", 
            "Optional": "from typing import Optional",
            "Union": "from typing import Union",
            "Tuple": "from typing import Tuple",
            "Any": "from typing import Any",
            "Callable": "from typing import Callable"
        }
        
        needed_imports = set()
        
        # æ£€æµ‹ç±»å‹æ³¨è§£ä¸­çš„typingç±»å‹
        for type_name, import_stmt in PYTHON_TYPE_IMPORTS.items():
            if f": {type_name}" in code_content or f"-> {type_name}" in code_content:
                needed_imports.add(import_stmt)
                
        return needed_imports
    
    def _get_allowed_helper_files(self, component_names: list) -> list:
        """
        æ ¹æ®ç»„ä»¶åç¡®å®šå…è®¸çš„helperæ–‡ä»¶
        
        Args:
            component_names: ç»„ä»¶ååˆ—è¡¨
            
        Returns:
            å…è®¸æŸ¥æ‰¾çš„helperæ–‡ä»¶ååˆ—è¡¨
        """
        if not component_names:
            return []
            
        allowed_files = []
        for component_name in component_names:
            if 'tfim' in component_name.lower():
                allowed_files.extend(['tfim_hamiltonian.py', 'tfim_hea_circuit.py'])
            elif 'heisenberg' in component_name.lower():
                allowed_files.extend(['heisenberg_hamiltonian.py', 'heisenberg_ansatz.py'])
            elif 'molecular' in component_name.lower() or 'uccsd' in component_name.lower():
                allowed_files.extend(['molecular_hamiltonian.py', 'uccsd_ansatz.py', 'molecular_vqe.py'])
        
        # ç®—æ³•ç»„ä»¶å…è®¸é€šç”¨æ–‡ä»¶
        for component_name in component_names:
            if 'vqe' in component_name.lower() or 'cobyla' in component_name.lower() or 'estimator' in component_name.lower():
                allowed_files.extend(['vqe_templates.py'])
        
        # å»é‡å¹¶è¿”å›
        return list(set(allowed_files))

    def _validate_parameter_completion(self, completed_params: Dict[str, Any], requirements: Dict[str, Any]) -> Dict[str, Any]:
        """
        éªŒè¯AIç”Ÿæˆçš„å‚æ•°è¡¥å…¨ç»“æœ
        
        Args:
            completed_params: AIè¡¥å…¨çš„å‚æ•°
            requirements: ç»„ä»¶å‚æ•°éœ€æ±‚
            
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        validation_result = {
            "valid": True,
            "errors": [],
            "warnings": [],
            "validated_params": {}
        }
        
        required_params = requirements.get("required_params", {})
        param_metadata = requirements.get("metadata", {})
        
        # éªŒè¯æ¯ä¸ªè¡¥å…¨çš„å‚æ•°
        for param_name, param_value in completed_params.items():
            # æ£€æŸ¥å‚æ•°æ˜¯å¦åœ¨éœ€æ±‚ä¸­
            if param_name not in required_params:
                validation_result["warnings"].append(f"å‚æ•° {param_name} ä¸åœ¨ç»„ä»¶éœ€æ±‚ä¸­")
                continue
            
            # è·å–å‚æ•°å…ƒæ•°æ®
            metadata = param_metadata.get(param_name, {})
            expected_type = metadata.get("type")
            param_enum = metadata.get("enum", [])
            
            # ç±»å‹éªŒè¯
            if expected_type:
                if expected_type == "int" and not isinstance(param_value, int):
                    try:
                        param_value = int(param_value)
                    except (ValueError, TypeError):
                        validation_result["errors"].append(f"å‚æ•° {param_name} åº”ä¸ºintç±»å‹")
                        validation_result["valid"] = False
                        continue
                        
                elif expected_type == "float" and not isinstance(param_value, (int, float)):
                    try:
                        param_value = float(param_value)
                    except (ValueError, TypeError):
                        validation_result["errors"].append(f"å‚æ•° {param_name} åº”ä¸ºfloatç±»å‹")
                        validation_result["valid"] = False
                        continue
                        
                elif expected_type == "str" and not isinstance(param_value, str):
                    param_value = str(param_value)
            
            # æšä¸¾å€¼éªŒè¯
            if param_enum and param_value not in param_enum:
                validation_result["errors"].append(f"å‚æ•° {param_name} å€¼ {param_value} ä¸åœ¨å…è®¸åˆ—è¡¨ {param_enum} ä¸­")
                validation_result["valid"] = False
                continue
            
            # éªŒè¯é€šè¿‡ï¼Œæ·»åŠ åˆ°ç»“æœ
            validation_result["validated_params"][param_name] = param_value
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç¼ºå¤±çš„å¿…éœ€å‚æ•°
        missing_required = []
        for param_name, metadata in param_metadata.items():
            if metadata.get("required", True) and param_name not in validation_result["validated_params"]:
                missing_required.append(param_name)
        
        if missing_required:
            validation_result["warnings"].append(f"ä»ç¼ºå°‘å¿…éœ€å‚æ•°: {missing_required}")
        
        return validation_result

    def generate_codecells(self, pipeline_plan: Dict[str, Any], components: List[Dict[str, Any]], param_map: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Agent 5: ä»£ç ç”Ÿæˆ - ç”ŸæˆCodeCellåˆ—è¡¨
        
        Args:
            pipeline_plan: ç®¡é“è®¡åˆ’
            components: ç»„ä»¶åˆ—è¡¨
            param_map: å‚æ•°æ˜ å°„
            
        Returns:
            CodeCellåˆ—è¡¨
        """
        # æå–å½“å‰ä»»åŠ¡éœ€è¦çš„helperå‡½æ•°ç­¾åå’Œæºä»£ç ä¿¡æ¯
        helper_signatures = {}
        helper_sources = {}
        # æå–ç»„ä»¶é©±åŠ¨çš„å¯¼å…¥åˆ—è¡¨ (ç”¨æˆ·å»ºè®®çš„è§£å†³æ–¹æ¡ˆ)
        component_imports = set()
        
        # è·å–ç»„ä»¶ååˆ—è¡¨ç”¨äºéš”ç¦»æŸ¥æ‰¾
        component_names = [c.get("name", "") for c in components]
        
        # æŒ‰ç…§Pipelineæ‰§è¡Œé¡ºåºå¤„ç†ç»„ä»¶
        execution_order = pipeline_plan.get("execution_order", [])
        ordered_components = []
        for component_name in execution_order:
            for comp in components:
                if comp.get("name") == component_name:
                    ordered_components.append(comp)
                    break
        
        # å¦‚æœexecution_orderä¸ºç©ºæˆ–ä¸å®Œæ•´ï¼Œfallbackåˆ°åŸå§‹é¡ºåº
        if len(ordered_components) != len(components):
            ordered_components = components
            
        for component in ordered_components:
            # ä¼˜å…ˆä½¿ç”¨helper_functionå­—æ®µï¼Œfallbackåˆ°codegen_hint.helper
            helper_name = component.get("helper_function") or component.get("codegen_hint", {}).get("helper")
            if helper_name:
                print(f"ğŸ” Looking for helper: {helper_name} (from component: {component.get('name')})")
                # ä»helperæ–‡ä»¶ä¸­åŠ¨æ€è·å–å‡½æ•°ç­¾å
                signature = self._get_helper_signature(helper_name)
                if signature:
                    helper_signatures[helper_name] = signature
                # è·å–helperå‡½æ•°æºä»£ç  (åªä»ç›¸å…³ç»„ä»¶çš„æ–‡ä»¶ä¸­æŸ¥æ‰¾)
                source_code = self._get_helper_source(helper_name, component_names)
                if source_code:
                    helper_sources[helper_name] = source_code
                    print(f"âœ… Found helper: {helper_name}")
                else:
                    print(f"âŒ Missing helper: {helper_name}")
            
            # æ”¶é›†æ¯ä¸ªç»„ä»¶çš„å¯¼å…¥ (åªç”¨ç»„ä»¶ä¸­å®šä¹‰çš„å¯¼å…¥)
            import_hint = component.get("codegen_hint", {}).get("import")
            if import_hint:
                # å¤„ç†åˆ†å·åˆ†éš”çš„å¤šä¸ªå¯¼å…¥
                if ';' in import_hint:
                    for single_import in import_hint.split(';'):
                        component_imports.add(single_import.strip())
                else:
                    component_imports.add(import_hint)
                print(f"ğŸ“¦ Added imports from {component.get('name')}: {import_hint}")
            
            # è‡ªåŠ¨æ£€æµ‹typing importséœ€æ±‚  
            params_schema = component.get("params_schema", {})
            typing_imports = self._detect_typing_imports(params_schema)
            for typing_import in typing_imports:
                component_imports.add(typing_import)
                if typing_imports:
                    print(f"ğŸ“ Auto-added typing imports from {component.get('name')}: {', '.join(typing_imports)}")

        # æ·»åŠ åŸºç¡€å¿…éœ€å¯¼å…¥
        component_imports.add("import numpy")
        component_imports.add("from qiskit.circuit import ParameterVector")
        component_imports.add("from qiskit.primitives import Estimator")
        component_imports.add("from qiskit_algorithms import VQE")
        component_imports.add("from qiskit_algorithms.optimizers import COBYLA")
        
        
        user_message = f"""PipelinePlan: {json.dumps(pipeline_plan, ensure_ascii=False)}

ComponentCards: {json.dumps(components, ensure_ascii=False, indent=2)}

ParamMap: {json.dumps(param_map, ensure_ascii=False)}

HelperSignatures: {json.dumps(helper_signatures, ensure_ascii=False)}

HelperSources: {json.dumps(helper_sources, ensure_ascii=False)}

ComponentImports: {list(component_imports)}

Please generate corresponding CodeCell for each component, including imports, helpers, definitions, invoke, and exports.

CRITICAL: helpers field must contain complete function definitions (def statements) for all helper functions used in invoke code.
Use the provided HelperSources for complete function implementations.

CRITICAL IMPORT RULE - COMPONENT-DRIVEN:
Use ONLY imports from ComponentImports list provided in the user message.
ComponentImports contains the exact imports needed for the selected components.

- For spin systems (TFIM/Heisenberg): ComponentImports will NOT include qiskit_nature
- For molecular systems: ComponentImports will include necessary qiskit_nature imports  
- For algorithms: ComponentImports includes the specific optimizers/primitives needed

Do NOT add any imports beyond ComponentImports list.
Do NOT use quantum computing knowledge to add "standard" imports.
ComponentImports is dynamically generated based on selected components - trust it completely.

For example, if invoke uses "H = build_tfim_h(n, hx, j)", copy the complete function from HelperSources.

Use the HelperSignatures to ensure correct function calls with proper parameter order."""
        
        for attempt in range(self.max_retries):
            try:
                response = self._call_openai(self.codegen_prompt, user_message, "CodegenAgent")
                parsed_data = self._parse_json_with_retry(response, "CodegenAgent")
                
                if self._validate_code_cells(parsed_data):
                    return parsed_data
                else:
                    raise ValueError("CodeCellsæ ¼å¼éªŒè¯å¤±è´¥")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"CodegenAgentå¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}")
                
                print(f"âš ï¸ CodegenAgenté‡è¯• {attempt + 1}/{self.max_retries}: {str(e)}")
                time.sleep(0.5)
    
    async def discover_and_normalize_parallel(self, task_card: Dict[str, Any], registry_data: List[Dict[str, Any]]) -> tuple:
        """
        å¹¶è¡Œæ‰§è¡Œç»„ä»¶å‘ç°å’Œåˆæ­¥å‚æ•°å½’ä¸€åŒ–
        
        Args:
            task_card: ä»»åŠ¡å¡
            registry_data: ç»„ä»¶æ³¨å†Œè¡¨æ•°æ®
            
        Returns:
            (components, initial_param_map) å…ƒç»„
        """
        # å‡†å¤‡å¹¶è¡Œä»»åŠ¡
        discovery_task = self._discover_components_async(task_card, registry_data)
        param_norm_task = self._normalize_params_initial_async(task_card)
        
        # å¹¶è¡Œæ‰§è¡Œ
        components, initial_param_map = await asyncio.gather(
            discovery_task, 
            param_norm_task,
            return_exceptions=True
        )
        
        # é”™è¯¯å¤„ç†
        if isinstance(components, Exception):
            raise RuntimeError(f"ç»„ä»¶å‘ç°å¹¶è¡Œæ‰§è¡Œå¤±è´¥: {components}")
        if isinstance(initial_param_map, Exception):
            raise RuntimeError(f"å‚æ•°å½’ä¸€åŒ–å¹¶è¡Œæ‰§è¡Œå¤±è´¥: {initial_param_map}")
            
        return components, initial_param_map
    
    async def _discover_components_async(self, task_card: Dict[str, Any], registry_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å¼‚æ­¥ç»„ä»¶å‘ç°"""
        user_message = f"""
TaskCard: {json.dumps(task_card, ensure_ascii=False)}

Component Registry: {json.dumps(registry_data, ensure_ascii=False)}

Please select appropriate components from the registry based on the TaskCard."""

        for attempt in range(self.max_retries):
            try:
                response = await self._call_openai_async(self.discovery_prompt, user_message)
                parsed_data = self._parse_json_with_retry(response, "DiscoveryAgent")
                
                if self._validate_component_cards(parsed_data):
                    return parsed_data
                else:
                    raise ValueError("ComponentCardsæ ¼å¼éªŒè¯å¤±è´¥")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"DiscoveryAgentå¼‚æ­¥è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}")
                
                await asyncio.sleep(0.5)
    
    async def _normalize_params_initial_async(self, task_card: Dict[str, Any]) -> Dict[str, Any]:
        """å¼‚æ­¥åˆæ­¥å‚æ•°å½’ä¸€åŒ–ï¼ˆä»…åŸºäºTaskCardï¼‰"""
        user_message = f"""
TaskCard: {json.dumps(task_card, ensure_ascii=False)}

Please perform initial parameter normalization for the TaskCard parameters, including alias mapping and default value injection."""

        for attempt in range(self.max_retries):
            try:
                response = await self._call_openai_async(self.param_norm_prompt, user_message)
                parsed_data = self._parse_json_with_retry(response, "ParamNormAgent")
                
                if self._validate_param_map(parsed_data):
                    return parsed_data
                else:
                    raise ValueError("ParamMapæ ¼å¼éªŒè¯å¤±è´¥")
            
            except Exception as e:
                if attempt == self.max_retries - 1:
                    raise RuntimeError(f"ParamNormAgentå¼‚æ­¥è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}")
                
                await asyncio.sleep(0.5)

    def get_agent_stats(self) -> Dict[str, Any]:
        """è·å–Agentä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "api_key_configured": bool(self.api_key),
            "max_retries": self.max_retries,
            "parallel_support": True,
            "supported_agents": [
                "SemanticAgent", "DiscoveryAgent", "ParamNormAgent", 
                "PipelineAgent", "CodegenAgent"
            ]
        }


# =============================================================================
# ä¾¿åˆ©å‡½æ•°
# =============================================================================

def create_engine(api_key: Optional[str] = None, max_retries: int = 3) -> LLMEngine:
    """
    åˆ›å»ºLLMå¼•æ“å®ä¾‹
    
    Args:
        api_key: OpenAI APIå¯†é’¥
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        LLMEngineå®ä¾‹
    """
    return LLMEngine(api_key=api_key, max_retries=max_retries)


# =============================================================================
# æµ‹è¯•ä»£ç 
# =============================================================================

if __name__ == "__main__":
    print("ğŸ§ª Testing LLMEngine...")
    
    try:
        # åˆ›å»ºå¼•æ“
        engine = create_engine()
        
        # æµ‹è¯•åŸºç¡€é…ç½®
        stats = engine.get_agent_stats()
        print("ğŸ“Š å¼•æ“é…ç½®:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        
        # æµ‹è¯•SemanticAgent
        test_query = "å¸®æˆ‘è®¡ç®—8æ¯”ç‰¹TFIMçš„åŸºæ€èƒ½é‡ï¼Œä½¿ç”¨VQEç®—æ³•"
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        print("ğŸ¤– è°ƒç”¨SemanticAgent...")
        task_card = engine.task_understanding(test_query)
        print(f"ğŸ“‹ TaskCard: {json.dumps(task_card, ensure_ascii=False, indent=2)}")
        
        # éªŒè¯TaskCardæ ¼å¼
        if engine._validate_task_card(task_card):
            print("âœ… TaskCardæ ¼å¼éªŒè¯é€šè¿‡ï¼")
        else:
            print("âŒ TaskCardæ ¼å¼éªŒè¯å¤±è´¥ï¼")
        
        print("\nğŸ‰ LLMEngineåŸºç¡€æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ“ æ³¨æ„ï¼šå®Œæ•´çš„Agentæµ‹è¯•éœ€è¦ç»„ä»¶æ³¨å†Œè¡¨æ•°æ®ã€‚")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print("ğŸ’¡ è¯·æ£€æŸ¥OPENAI_API_KEYç¯å¢ƒå˜é‡é…ç½®ã€‚")