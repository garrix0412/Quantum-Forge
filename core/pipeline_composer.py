"""
ç®¡é“ç¼–æ’å™¨ - QuantumForge vNext

åŸºäºç»„ä»¶ä¾èµ–å…³ç³»ç”Ÿæˆçº¿æ€§æ‰§è¡Œè®¡åˆ’ã€‚
åŸºäºnew.mdç¬¬4.6èŠ‚è§„æ ¼å’ŒPipelinePlanæ¶æ„å®ç°ã€‚
"""

from typing import Dict, List, Any, Set
try:
    from .llm_engine import create_engine
    from .schemas import PipelinePlan, PipelineStep
except ImportError:
    # ç›´æ¥è¿è¡Œæ—¶çš„å…¼å®¹å¤„ç†
    import sys
    import os
    sys.path.append(os.path.dirname(__file__))
    from llm_engine import create_engine
    from schemas import PipelinePlan, PipelineStep


def compose(task_card: Dict[str, Any], components: List[Dict[str, Any]], param_map: Dict[str, Any]) -> Dict[str, Any]:
    """
    ç¼–æ’ç»„ä»¶æ‰§è¡Œç®¡é“
    
    Args:
        task_card: ä»»åŠ¡å¡
        components: ç»„ä»¶åˆ—è¡¨
        param_map: å‚æ•°æ˜ å°„
        
    Returns:
        PipelinePlanå­—å…¸
    """
    # åˆ›å»ºLLMå¼•æ“
    engine = create_engine()
    
    # è°ƒç”¨PipelineAgent
    pipeline_plan = engine.plan_pipeline(task_card, components, param_map)
    
    # åº”ç”¨æœ¬åœ°æ‹“æ‰‘æ’åºéªŒè¯å’Œä¼˜åŒ–
    enhanced_plan = _apply_local_topological_sort(pipeline_plan, components)
    
    return enhanced_plan


def _apply_local_topological_sort(pipeline_plan: Dict[str, Any], components: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    åº”ç”¨æœ¬åœ°æ‹“æ‰‘æ’åºéªŒè¯
    
    Args:
        pipeline_plan: Agentè¿”å›çš„ç®¡é“è®¡åˆ’
        components: ç»„ä»¶åˆ—è¡¨
        
    Returns:
        ä¼˜åŒ–åçš„ç®¡é“è®¡åˆ’
    """
    # æ„å»ºç»„ä»¶ä¾èµ–å›¾
    component_map = {comp["name"]: comp for comp in components}
    dependency_graph = {}
    provides_map = {}
    
    for comp in components:
        name = comp["name"]
        needs = comp.get("needs", [])
        provides = comp.get("provides", [])
        
        dependency_graph[name] = needs
        for resource in provides:
            if resource not in provides_map:
                provides_map[resource] = []
            provides_map[resource].append(name)
    
    # æ‰§è¡Œæ‹“æ‰‘æ’åº
    sorted_order = topological_sort(dependency_graph, provides_map)
    
    # æ£€æµ‹å†²çª
    conflicts = detect_conflicts(components, provides_map)
    
    # æ„å»ºå¢å¼ºçš„ç®¡é“è®¡åˆ’
    enhanced_plan = {
        "execution_order": sorted_order,
        "dependency_graph": dependency_graph,
        "conflicts": conflicts,
        "provides_map": provides_map,
        "original_order": pipeline_plan.get("execution_order", [])
    }
    
    return enhanced_plan


def topological_sort(dependency_graph: Dict[str, List[str]], provides_map: Dict[str, List[str]]) -> List[str]:
    """
    æ‹“æ‰‘æ’åºç®—æ³•
    
    Args:
        dependency_graph: ä¾èµ–å…³ç³»å›¾ {ç»„ä»¶å: [éœ€è¦çš„èµ„æº]}
        provides_map: æä¾›å…³ç³»å›¾ {èµ„æºå: [æä¾›è¯¥èµ„æºçš„ç»„ä»¶]}
        
    Returns:
        æ‹“æ‰‘æ’åºåçš„ç»„ä»¶æ‰§è¡Œé¡ºåº
    """
    # æ„å»ºç»„ä»¶é—´ç›´æ¥ä¾èµ–å…³ç³»
    component_deps = {}
    for comp_name, needed_resources in dependency_graph.items():
        component_deps[comp_name] = set()
        
        for resource in needed_resources:
            if resource in provides_map:
                # è¿™ä¸ªç»„ä»¶ä¾èµ–äºæä¾›è¯¥èµ„æºçš„æ‰€æœ‰ç»„ä»¶
                component_deps[comp_name].update(provides_map[resource])
    
    # Kahnç®—æ³•è¿›è¡Œæ‹“æ‰‘æ’åº
    in_degree = {comp: 0 for comp in dependency_graph.keys()}
    
    # è®¡ç®—å…¥åº¦
    for comp_name, deps in component_deps.items():
        for dep in deps:
            if dep in in_degree:
                in_degree[comp_name] += 1
    
    # åˆå§‹åŒ–é˜Ÿåˆ—ï¼ˆå…¥åº¦ä¸º0çš„èŠ‚ç‚¹ï¼‰
    queue = [comp for comp, degree in in_degree.items() if degree == 0]
    result = []
    
    while queue:
        # å–å‡ºä¸€ä¸ªå…¥åº¦ä¸º0çš„èŠ‚ç‚¹
        current = queue.pop(0)
        result.append(current)
        
        # æ›´æ–°ç›¸é‚»èŠ‚ç‚¹çš„å…¥åº¦
        for comp_name, deps in component_deps.items():
            if current in deps:
                in_degree[comp_name] -= 1
                if in_degree[comp_name] == 0:
                    queue.append(comp_name)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¯
    if len(result) != len(dependency_graph):
        remaining = set(dependency_graph.keys()) - set(result)
        raise ValueError(f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–: {remaining}")
    
    return result


def detect_conflicts(components: List[Dict[str, Any]], provides_map: Dict[str, List[str]]) -> List[str]:
    """
    æ£€æµ‹èµ„æºæä¾›å†²çª
    
    Args:
        components: ç»„ä»¶åˆ—è¡¨
        provides_map: èµ„æºæä¾›æ˜ å°„
        
    Returns:
        å†²çªæè¿°åˆ—è¡¨
    """
    conflicts = []
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¤šä¸ªç»„ä»¶æä¾›åŒä¸€èµ„æº
    for resource, providers in provides_map.items():
        if len(providers) > 1:
            conflicts.append(f"èµ„æº '{resource}' ç”±å¤šä¸ªç»„ä»¶æä¾›: {providers}")
    
    return conflicts


def compose_to_dataclass(task_card: Dict[str, Any], components: List[Dict[str, Any]], param_map: Dict[str, Any]) -> PipelinePlan:
    """
    ç¼–æ’ç®¡é“å¹¶è½¬æ¢ä¸ºæ•°æ®ç±»
    
    Args:
        task_card: ä»»åŠ¡å¡
        components: ç»„ä»¶åˆ—è¡¨
        param_map: å‚æ•°æ˜ å°„
        
    Returns:
        PipelinePlanæ•°æ®ç±»å®ä¾‹
    """
    pipeline_dict = compose(task_card, components, param_map)
    
    # æ„å»ºPipelineStepåˆ—è¡¨
    steps = []
    execution_order = pipeline_dict["execution_order"]
    normalized_params = param_map.get("normalized_params", {})
    
    for comp_name in execution_order:
        # ä¸ºæ¯ä¸ªç»„ä»¶åˆ›å»ºå‚æ•°ç»‘å®šï¼ˆä½¿ç”¨$paramå ä½ç¬¦ï¼‰
        comp_params = {}
        
        # æ‰¾åˆ°å¯¹åº”çš„ç»„ä»¶
        component = None
        for comp in components:
            if comp["name"] == comp_name:
                component = comp
                break
        
        if component:
            params_schema = component.get("params_schema", {})
            for param_name in params_schema.keys():
                if param_name in normalized_params:
                    comp_params[param_name] = f"${param_name}"
        
        step = PipelineStep(use=comp_name, with_params=comp_params)
        steps.append(step)
    
    return PipelinePlan(steps=steps)


def validate_pipeline(pipeline_plan: Dict[str, Any], components: List[Dict[str, Any]]) -> List[str]:
    """
    éªŒè¯ç®¡é“è®¡åˆ’çš„æœ‰æ•ˆæ€§
    
    Args:
        pipeline_plan: ç®¡é“è®¡åˆ’
        components: ç»„ä»¶åˆ—è¡¨
        
    Returns:
        éªŒè¯é”™è¯¯åˆ—è¡¨
    """
    errors = []
    
    execution_order = pipeline_plan.get("execution_order", [])
    component_names = {comp["name"] for comp in components}
    
    # æ£€æŸ¥æ‰§è¡Œé¡ºåºä¸­çš„ç»„ä»¶æ˜¯å¦éƒ½å­˜åœ¨
    for comp_name in execution_order:
        if comp_name not in component_names:
            errors.append(f"æ‰§è¡Œè®¡åˆ’ä¸­çš„ç»„ä»¶ '{comp_name}' åœ¨ç»„ä»¶åˆ—è¡¨ä¸­ä¸å­˜åœ¨")
    
    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç»„ä»¶éƒ½åœ¨æ‰§è¡Œè®¡åˆ’ä¸­
    for comp in components:
        if comp["name"] not in execution_order:
            errors.append(f"ç»„ä»¶ '{comp['name']}' ä¸åœ¨æ‰§è¡Œè®¡åˆ’ä¸­")
    
    return errors


# =============================================================================
# æµ‹è¯•ä»£ç 
# =============================================================================

if __name__ == "__main__":
    print("ğŸ§ª Testing PipelineComposer...")
    
    # æµ‹è¯•æ•°æ®
    test_task_card = {
        "domain": "spin",
        "problem": "tfim_ground_energy",
        "algorithm": "vqe",
        "backend": "qiskit",
        "params": {"n": 8, "hx": 1.0, "j": 1.0}
    }
    
    test_components = [
        {
            "name": "Hamiltonian.TFIM",
            "kind": "hamiltonian",
            "needs": [],
            "provides": ["hamiltonian"]
        },
        {
            "name": "Circuit.TFIM_HEA", 
            "kind": "ansatz",
            "needs": [],
            "provides": ["ansatz"]
        },
        {
            "name": "Algorithm.VQE",
            "kind": "algorithm", 
            "needs": ["hamiltonian", "ansatz", "optimizer", "estimator"],
            "provides": ["energy", "result"]
        },
        {
            "name": "Optimizer.COBYLA",
            "kind": "optimizer",
            "needs": [],
            "provides": ["optimizer"]
        },
        {
            "name": "Backend.Estimator",
            "kind": "backend",
            "needs": [],
            "provides": ["estimator"]
        }
    ]
    
    test_param_map = {
        "normalized_params": {"n": 8, "hx": 1.0, "j": 1.0},
        "aliases": {"num_qubits": "n"},
        "defaults": {"optimizer": "COBYLA"},
        "validation_errors": []
    }
    
    print(f"ğŸ“‹ ä»»åŠ¡: {test_task_card['domain']}.{test_task_card['problem']}")
    print(f"ğŸ”§ ç»„ä»¶æ•°é‡: {len(test_components)}")
    
    try:
        # æµ‹è¯•ç®¡é“ç¼–æ’
        pipeline_plan = compose(test_task_card, test_components, test_param_map)
        
        print(f"\nğŸ“Š æ‰§è¡Œé¡ºåº: {pipeline_plan['execution_order']}")
        print(f"ğŸ”— ä¾èµ–å…³ç³»: {pipeline_plan['dependency_graph']}")
        
        if pipeline_plan['conflicts']:
            print(f"âš ï¸ æ£€æµ‹åˆ°å†²çª: {pipeline_plan['conflicts']}")
        else:
            print("âœ… æ— å†²çªæ£€æµ‹")
        
        # éªŒè¯ç®¡é“è®¡åˆ’
        validation_errors = validate_pipeline(pipeline_plan, test_components)
        if validation_errors:
            print(f"âŒ ç®¡é“éªŒè¯å¤±è´¥: {validation_errors}")
        else:
            print("âœ… ç®¡é“éªŒè¯é€šè¿‡")
        
        # æµ‹è¯•æ•°æ®ç±»è½¬æ¢
        pipeline_obj = compose_to_dataclass(test_task_card, test_components, test_param_map)
        print(f"\nğŸ“¦ PipelinePlanå¯¹è±¡: {len(pipeline_obj.steps)}ä¸ªæ­¥éª¤")
        
        # æ˜¾ç¤ºæ­¥éª¤è¯¦æƒ…
        for i, step in enumerate(pipeline_obj.steps):
            print(f"   æ­¥éª¤{i+1}: {step.use} -> {step.with_params}")
        
        print("\nâœ… PipelineComposeræµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"âŒ ç®¡é“ç¼–æ’å¤±è´¥: {str(e)}")
        print("ğŸ’¡ è¯·æ£€æŸ¥OPENAI_API_KEYç¯å¢ƒå˜é‡é…ç½®ã€‚")